version: '3.8'

services:
  # Neo4j Database - Shared between both servers
  neo4j:
    image: neo4j:5.26.2
    container_name: graphiti-neo4j
    restart: unless-stopped
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "wget -qO- http://localhost:7474 || exit 1",
        ]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 30s
    ports:
      - "7474:7474"  # HTTP - Neo4j Browser
      - "7687:7687"  # Bolt - Database connections
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
    environment:
      - NEO4J_AUTH=${NEO4J_USER:-neo4j}/${NEO4J_PASSWORD:-your_secure_password}
      - NEO4J_server_memory_heap_initial__size=1G
      - NEO4J_server_memory_heap_max__size=2G
      - NEO4J_server_memory_pagecache_size=1G
      - NEO4J_server_default__listen__address=0.0.0.0
      - NEO4J_server_bolt_listen__address=0.0.0.0:7687
      - NEO4J_server_http_listen__address=0.0.0.0:7474
    networks:
      - graphiti-network

  # Graphiti Knowledge Server (REST API)
  graphiti-server:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: graphiti-knowledge-server
    restart: unless-stopped
    ports:
      - "8000:8000"  # REST API
    healthcheck:
      test:
        [
          "CMD",
          "python",
          "-c",
          "import urllib.request; urllib.request.urlopen('http://localhost:8000/healthcheck')",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    depends_on:
      neo4j:
        condition: service_healthy
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_BASE_URL=${OPENAI_BASE_URL:-}
      - MODEL_NAME=${MODEL_NAME:-gpt-4o-mini}
      - EMBEDDING_MODEL_NAME=${EMBEDDING_MODEL_NAME:-text-embedding-3-small}
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=${NEO4J_USER:-neo4j}
      - NEO4J_PASSWORD=${NEO4J_PASSWORD:-your_secure_password}
      - PORT=8000
      - PYTHONUNBUFFERED=1
    networks:
      - graphiti-network
    volumes:
      - ./logs:/app/logs

  # Graphiti MCP Server
  graphiti-mcp:
    build:
      context: ./mcp_server
      dockerfile: Dockerfile
    container_name: graphiti-mcp-server
    restart: unless-stopped
    ports:
      - "8001:8000"  # MCP Server (different port to avoid conflict)
    healthcheck:
      test:
        [
          "CMD",
          "python",
          "-c",
          "import urllib.request; urllib.request.urlopen('http://localhost:8000/healthcheck')",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    depends_on:
      neo4j:
        condition: service_healthy
    environment:
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=${NEO4J_USER:-neo4j}
      - NEO4J_PASSWORD=${NEO4J_PASSWORD:-your_secure_password}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_BASE_URL=${OPENAI_BASE_URL:-}
      - MODEL_NAME=${MODEL_NAME:-gpt-4o-mini}
      - SMALL_MODEL_NAME=${SMALL_MODEL_NAME:-gpt-4o-mini}
      - LLM_TEMPERATURE=${LLM_TEMPERATURE:-0.0}
      - SEMAPHORE_LIMIT=${SEMAPHORE_LIMIT:-10}
      - PYTHONUNBUFFERED=1
      - MCP_SERVER_HOST=0.0.0.0
    networks:
      - graphiti-network
    volumes:
      - ./logs:/app/logs
    command: ["uv", "run", "graphiti_mcp_server.py", "--transport", "sse"]

volumes:
  neo4j_data:
    driver: local
  neo4j_logs:
    driver: local

networks:
  graphiti-network:
    driver: bridge 